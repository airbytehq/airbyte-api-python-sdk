"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
import dateutil.parser
from airbyte_api import utils
from dataclasses_json import Undefined, dataclass_json
from datetime import datetime
from enum import Enum
from typing import Final, List, Optional


class AWSSellerPartnerAccountType(str, Enum):
    r"""Type of the Account you're going to authorize the Airbyte application by"""
    SELLER = 'Seller'
    VENDOR = 'Vendor'


class SourceAmazonSellerPartnerAuthType(str, Enum):
    OAUTH2_0 = 'oauth2.0'


class AWSEnvironment(str, Enum):
    r"""Select the AWS Environment."""
    PRODUCTION = 'PRODUCTION'
    SANDBOX = 'SANDBOX'


class FinancialEventsStepSizeInDays(str, Enum):
    r"""The time window size (in days) for fetching financial events data in chunks. Options are 1 day, 7 days, 14 days, 30 days, 60 days, and 190 days, based on API limitations.

    - **Smaller step sizes (e.g., 1 day)** are better for large data volumes. They fetch smaller chunks per request, reducing the risk of timeouts or overwhelming the API, though more requests may slow syncing and increase the chance of hitting rate limits.
    - **Larger step sizes (e.g., 14 days)** are better for smaller data volumes. They fetch more data per request, speeding up syncing and reducing the number of API calls, which minimizes strain on rate limits.

    Select a step size that matches your data volume to optimize syncing speed and API performance.
    """
    ONE = '1'
    SEVEN = '7'
    FOURTEEN = '14'
    THIRTY = '30'
    SIXTY = '60'
    NINETY = '90'
    ONE_HUNDRED_AND_EIGHTY = '180'


class AWSRegion(str, Enum):
    r"""Select the AWS Region."""
    AE = 'AE'
    AU = 'AU'
    BE = 'BE'
    BR = 'BR'
    CA = 'CA'
    DE = 'DE'
    EG = 'EG'
    ES = 'ES'
    FR = 'FR'
    GB = 'GB'
    IN = 'IN'
    IT = 'IT'
    JP = 'JP'
    MX = 'MX'
    NL = 'NL'
    PL = 'PL'
    SA = 'SA'
    SE = 'SE'
    SG = 'SG'
    TR = 'TR'
    UK = 'UK'
    US = 'US'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class OptionsList:
    option_name: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('option_name') }})
    option_value: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('option_value') }})
    



class ReportName(str, Enum):
    GET_AFN_INVENTORY_DATA = 'GET_AFN_INVENTORY_DATA'
    GET_AFN_INVENTORY_DATA_BY_COUNTRY = 'GET_AFN_INVENTORY_DATA_BY_COUNTRY'
    GET_AMAZON_FULFILLED_SHIPMENTS_DATA_GENERAL = 'GET_AMAZON_FULFILLED_SHIPMENTS_DATA_GENERAL'
    GET_FBA_ESTIMATED_FBA_FEES_TXT_DATA = 'GET_FBA_ESTIMATED_FBA_FEES_TXT_DATA'
    GET_FBA_FULFILLMENT_CUSTOMER_RETURNS_DATA = 'GET_FBA_FULFILLMENT_CUSTOMER_RETURNS_DATA'
    GET_FBA_FULFILLMENT_CUSTOMER_SHIPMENT_PROMOTION_DATA = 'GET_FBA_FULFILLMENT_CUSTOMER_SHIPMENT_PROMOTION_DATA'
    GET_FBA_FULFILLMENT_CUSTOMER_SHIPMENT_REPLACEMENT_DATA = 'GET_FBA_FULFILLMENT_CUSTOMER_SHIPMENT_REPLACEMENT_DATA'
    GET_FBA_FULFILLMENT_REMOVAL_ORDER_DETAIL_DATA = 'GET_FBA_FULFILLMENT_REMOVAL_ORDER_DETAIL_DATA'
    GET_FBA_FULFILLMENT_REMOVAL_SHIPMENT_DETAIL_DATA = 'GET_FBA_FULFILLMENT_REMOVAL_SHIPMENT_DETAIL_DATA'
    GET_FBA_INVENTORY_PLANNING_DATA = 'GET_FBA_INVENTORY_PLANNING_DATA'
    GET_FBA_MYI_UNSUPPRESSED_INVENTORY_DATA = 'GET_FBA_MYI_UNSUPPRESSED_INVENTORY_DATA'
    GET_FBA_REIMBURSEMENTS_DATA = 'GET_FBA_REIMBURSEMENTS_DATA'
    GET_FBA_SNS_FORECAST_DATA = 'GET_FBA_SNS_FORECAST_DATA'
    GET_FBA_SNS_PERFORMANCE_DATA = 'GET_FBA_SNS_PERFORMANCE_DATA'
    GET_FBA_STORAGE_FEE_CHARGES_DATA = 'GET_FBA_STORAGE_FEE_CHARGES_DATA'
    GET_FLAT_FILE_ACTIONABLE_ORDER_DATA_SHIPPING = 'GET_FLAT_FILE_ACTIONABLE_ORDER_DATA_SHIPPING'
    GET_FLAT_FILE_ALL_ORDERS_DATA_BY_LAST_UPDATE_GENERAL = 'GET_FLAT_FILE_ALL_ORDERS_DATA_BY_LAST_UPDATE_GENERAL'
    GET_FLAT_FILE_ALL_ORDERS_DATA_BY_ORDER_DATE_GENERAL = 'GET_FLAT_FILE_ALL_ORDERS_DATA_BY_ORDER_DATE_GENERAL'
    GET_FLAT_FILE_ARCHIVED_ORDERS_DATA_BY_ORDER_DATE = 'GET_FLAT_FILE_ARCHIVED_ORDERS_DATA_BY_ORDER_DATE'
    GET_FLAT_FILE_OPEN_LISTINGS_DATA = 'GET_FLAT_FILE_OPEN_LISTINGS_DATA'
    GET_FLAT_FILE_RETURNS_DATA_BY_RETURN_DATE = 'GET_FLAT_FILE_RETURNS_DATA_BY_RETURN_DATE'
    GET_LEDGER_DETAIL_VIEW_DATA = 'GET_LEDGER_DETAIL_VIEW_DATA'
    GET_LEDGER_SUMMARY_VIEW_DATA = 'GET_LEDGER_SUMMARY_VIEW_DATA'
    GET_MERCHANT_CANCELLED_LISTINGS_DATA = 'GET_MERCHANT_CANCELLED_LISTINGS_DATA'
    GET_MERCHANT_LISTINGS_ALL_DATA = 'GET_MERCHANT_LISTINGS_ALL_DATA'
    GET_MERCHANT_LISTINGS_DATA = 'GET_MERCHANT_LISTINGS_DATA'
    GET_MERCHANT_LISTINGS_DATA_BACK_COMPAT = 'GET_MERCHANT_LISTINGS_DATA_BACK_COMPAT'
    GET_MERCHANT_LISTINGS_INACTIVE_DATA = 'GET_MERCHANT_LISTINGS_INACTIVE_DATA'
    GET_MERCHANTS_LISTINGS_FYP_REPORT = 'GET_MERCHANTS_LISTINGS_FYP_REPORT'
    GET_ORDER_REPORT_DATA_SHIPPING = 'GET_ORDER_REPORT_DATA_SHIPPING'
    GET_RESTOCK_INVENTORY_RECOMMENDATIONS_REPORT = 'GET_RESTOCK_INVENTORY_RECOMMENDATIONS_REPORT'
    GET_SELLER_FEEDBACK_DATA = 'GET_SELLER_FEEDBACK_DATA'
    GET_STRANDED_INVENTORY_UI_DATA = 'GET_STRANDED_INVENTORY_UI_DATA'
    GET_V2_SETTLEMENT_REPORT_DATA_FLAT_FILE = 'GET_V2_SETTLEMENT_REPORT_DATA_FLAT_FILE'
    GET_XML_ALL_ORDERS_DATA_BY_ORDER_DATE_GENERAL = 'GET_XML_ALL_ORDERS_DATA_BY_ORDER_DATE_GENERAL'
    GET_XML_BROWSE_TREE_DATA = 'GET_XML_BROWSE_TREE_DATA'
    GET_VENDOR_REAL_TIME_INVENTORY_REPORT = 'GET_VENDOR_REAL_TIME_INVENTORY_REPORT'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class ReportOptions:
    options_list: List[OptionsList] = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('options_list') }})
    r"""List of options"""
    report_name: ReportName = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('report_name') }})
    stream_name: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('stream_name') }})
    



class SourceAmazonSellerPartnerAmazonSellerPartner(str, Enum):
    AMAZON_SELLER_PARTNER = 'amazon-seller-partner'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class SourceAmazonSellerPartner:
    lwa_app_id: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('lwa_app_id') }})
    r"""Your Login with Amazon Client ID."""
    lwa_client_secret: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('lwa_client_secret') }})
    r"""Your Login with Amazon Client Secret."""
    refresh_token: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('refresh_token') }})
    r"""The Refresh Token obtained via OAuth flow authorization."""
    account_type: Optional[AWSSellerPartnerAccountType] = dataclasses.field(default=AWSSellerPartnerAccountType.SELLER, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('account_type'), 'exclude': lambda f: f is None }})
    r"""Type of the Account you're going to authorize the Airbyte application by"""
    app_id: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('app_id'), 'exclude': lambda f: f is None }})
    r"""Your Amazon Application ID."""
    AUTH_TYPE: Final[Optional[SourceAmazonSellerPartnerAuthType]] = dataclasses.field(default=SourceAmazonSellerPartnerAuthType.OAUTH2_0, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('auth_type'), 'exclude': lambda f: f is None }})
    aws_environment: Optional[AWSEnvironment] = dataclasses.field(default=AWSEnvironment.PRODUCTION, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('aws_environment'), 'exclude': lambda f: f is None }})
    r"""Select the AWS Environment."""
    financial_events_step: Optional[FinancialEventsStepSizeInDays] = dataclasses.field(default=FinancialEventsStepSizeInDays.ONE_HUNDRED_AND_EIGHTY, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('financial_events_step'), 'exclude': lambda f: f is None }})
    r"""The time window size (in days) for fetching financial events data in chunks. Options are 1 day, 7 days, 14 days, 30 days, 60 days, and 190 days, based on API limitations.

    - **Smaller step sizes (e.g., 1 day)** are better for large data volumes. They fetch smaller chunks per request, reducing the risk of timeouts or overwhelming the API, though more requests may slow syncing and increase the chance of hitting rate limits.
    - **Larger step sizes (e.g., 14 days)** are better for smaller data volumes. They fetch more data per request, speeding up syncing and reducing the number of API calls, which minimizes strain on rate limits.

    Select a step size that matches your data volume to optimize syncing speed and API performance.
    """
    max_async_job_count: Optional[int] = dataclasses.field(default=2, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('max_async_job_count'), 'exclude': lambda f: f is None }})
    r"""The maximum number of concurrent asynchronous job requests that can be active at a time."""
    num_workers: Optional[int] = dataclasses.field(default=2, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('num_workers'), 'exclude': lambda f: f is None }})
    r"""The number of workers to use for the connector when syncing concurrently."""
    period_in_days: Optional[int] = dataclasses.field(default=90, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('period_in_days'), 'exclude': lambda f: f is None }})
    r"""For syncs spanning a large date range, this option is used to request data in a smaller fixed window to improve sync reliability. This time window can be configured granularly by day."""
    region: Optional[AWSRegion] = dataclasses.field(default=AWSRegion.US, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('region'), 'exclude': lambda f: f is None }})
    r"""Select the AWS Region."""
    replication_end_date: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('replication_end_date'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'exclude': lambda f: f is None }})
    r"""UTC date and time in the format 2017-01-25T00:00:00Z. Any data after this date will not be replicated."""
    replication_start_date: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('replication_start_date'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'exclude': lambda f: f is None }})
    r"""UTC date and time in the format 2017-01-25T00:00:00Z. Any data before this date will not be replicated. If start date is not provided or older than 2 years ago from today, the date 2 years ago from today will be used."""
    report_options_list: Optional[List[ReportOptions]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('report_options_list'), 'exclude': lambda f: f is None }})
    r"""Additional information passed to reports. This varies by report type."""
    SOURCE_TYPE: Final[SourceAmazonSellerPartnerAmazonSellerPartner] = dataclasses.field(default=SourceAmazonSellerPartnerAmazonSellerPartner.AMAZON_SELLER_PARTNER, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('sourceType') }})
    wait_to_avoid_fatal_errors: Optional[bool] = dataclasses.field(default=False, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('wait_to_avoid_fatal_errors'), 'exclude': lambda f: f is None }})
    r"""For report based streams with known amount of requests per time period, this option will use waiting time between requests to avoid fatal statuses in reports. See <a href=\\"https://docs.airbyte.com/integrations/sources/amazon-seller-partner#limitations--troubleshooting\\" target=\\"_blank\\">Troubleshooting</a> section for more details"""
    

