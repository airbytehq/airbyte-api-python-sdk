"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from airbyte_api import utils
from dataclasses_json import Undefined, dataclass_json
from enum import Enum
from typing import Any, Final, List, Optional


class Serpstat(str, Enum):
    SERPSTAT = 'serpstat'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class SourceSerpstat:
    api_key: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('api_key') }})
    r"""Serpstat API key can be found here: https://serpstat.com/users/profile/"""
    domain: Optional[str] = dataclasses.field(default='serpstat.com', metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('domain'), 'exclude': lambda f: f is None }})
    r"""The domain name to get data for (ex. serpstat.com)"""
    domains: Optional[List[Any]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('domains'), 'exclude': lambda f: f is None }})
    r"""The list of domains that will be used in streams that support batch operations"""
    filter_by: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('filter_by'), 'exclude': lambda f: f is None }})
    r"""The field name by which the results should be filtered. Filtering the results will result in fewer API credits spent. Each stream has different filtering options. See https://serpstat.com/api/ for more details."""
    filter_value: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('filter_value'), 'exclude': lambda f: f is None }})
    r"""The value of the field to filter by. Each stream has different filtering options. See https://serpstat.com/api/ for more details."""
    page_size: Optional[int] = dataclasses.field(default=10, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('page_size'), 'exclude': lambda f: f is None }})
    r"""The number of data rows per page to be returned. Each data row can contain multiple data points. The max value is 1000. Reducing the size of the page will result in fewer API credits spent."""
    pages_to_fetch: Optional[int] = dataclasses.field(default=1, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('pages_to_fetch'), 'exclude': lambda f: f is None }})
    r"""The number of pages that should be fetched. All results will be obtained if left blank. Reducing the number of pages will result in fewer API credits spent."""
    region_id: Optional[str] = dataclasses.field(default='g_us', metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('region_id'), 'exclude': lambda f: f is None }})
    r"""The ID of a region to get data from in the form of a two-letter country code prepended with the g_ prefix. See the list of supported region IDs here: https://serpstat.com/api/664-request-parameters-v4/."""
    sort_by: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('sort_by'), 'exclude': lambda f: f is None }})
    r"""The field name by which the results should be sorted. Each stream has different sorting options. See https://serpstat.com/api/ for more details."""
    sort_value: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('sort_value'), 'exclude': lambda f: f is None }})
    r"""The value of the field to sort by. Each stream has different sorting options. See https://serpstat.com/api/ for more details."""
    SOURCE_TYPE: Final[Serpstat] = dataclasses.field(default=Serpstat.SERPSTAT, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('sourceType') }})
    

