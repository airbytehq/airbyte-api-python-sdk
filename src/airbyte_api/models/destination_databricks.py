"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from airbyte_api import utils
from dataclasses_json import Undefined, dataclass_json
from enum import Enum
from typing import Final, Optional, Union


class DestinationDatabricksAuthType(str, Enum):
    BASIC = 'BASIC'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class PersonalAccessToken:
    personal_access_token: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('personal_access_token') }})
    AUTH_TYPE: Final[DestinationDatabricksAuthType] = dataclasses.field(default=DestinationDatabricksAuthType.BASIC, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('auth_type') }})
    



class DestinationDatabricksSchemasAuthType(str, Enum):
    OAUTH = 'OAUTH'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class OAuth2Recommended:
    client_id: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('client_id') }})
    secret: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('secret') }})
    AUTH_TYPE: Final[DestinationDatabricksSchemasAuthType] = dataclasses.field(default=DestinationDatabricksSchemasAuthType.OAUTH, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('auth_type') }})
    



class Databricks(str, Enum):
    DATABRICKS = 'databricks'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class DestinationDatabricks:
    authentication: Authentication = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('authentication') }})
    r"""Authentication mechanism for Staging files and running queries"""
    database: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('database') }})
    r"""The name of the unity catalog for the database"""
    hostname: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('hostname') }})
    r"""Databricks Cluster Server Hostname."""
    http_path: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('http_path') }})
    r"""Databricks Cluster HTTP Path."""
    accept_terms: Optional[bool] = dataclasses.field(default=False, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('accept_terms'), 'exclude': lambda f: f is None }})
    r"""You must agree to the Databricks JDBC Driver <a href=\\"https://databricks.com/jdbc-odbc-driver-license\\">Terms & Conditions</a> to use this connector."""
    DESTINATION_TYPE: Final[Databricks] = dataclasses.field(default=Databricks.DATABRICKS, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('destinationType') }})
    port: Optional[str] = dataclasses.field(default='443', metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('port'), 'exclude': lambda f: f is None }})
    r"""Databricks Cluster Port."""
    purge_staging_data: Optional[bool] = dataclasses.field(default=True, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('purge_staging_data'), 'exclude': lambda f: f is None }})
    r"""Default to 'true'. Switch it to 'false' for debugging purpose."""
    raw_schema_override: Optional[str] = dataclasses.field(default='airbyte_internal', metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('raw_schema_override'), 'exclude': lambda f: f is None }})
    r"""The schema to write raw tables into (default: airbyte_internal)"""
    schema: Optional[str] = dataclasses.field(default='default', metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('schema'), 'exclude': lambda f: f is None }})
    r"""The default schema tables are written. If not specified otherwise, the \\"default\\" will be used."""
    


Authentication = Union[OAuth2Recommended, PersonalAccessToken]
