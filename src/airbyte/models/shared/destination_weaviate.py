"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from airbyte import utils
from dataclasses_json import Undefined, dataclass_json
from enum import Enum
from typing import Final, List, Optional, Union

class Weaviate(str, Enum):
    WEAVIATE = 'weaviate'

class DestinationWeaviateSchemasEmbeddingEmbedding7Mode(str, Enum):
    OPENAI_COMPATIBLE = 'openai_compatible'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class DestinationWeaviateOpenAICompatible:
    r"""Use a service that's compatible with the OpenAI API to embed text."""
    base_url: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('base_url') }})
    r"""The base URL for your OpenAI-compatible service"""
    dimensions: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('dimensions') }})
    r"""The number of dimensions the embedding model is generating"""
    api_key: Optional[str] = dataclasses.field(default='', metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('api_key'), 'exclude': lambda f: f is None }})
    MODE: Final[Optional[DestinationWeaviateSchemasEmbeddingEmbedding7Mode]] = dataclasses.field(default=DestinationWeaviateSchemasEmbeddingEmbedding7Mode.OPENAI_COMPATIBLE, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('mode'), 'exclude': lambda f: f is None }})
    model_name: Optional[str] = dataclasses.field(default='text-embedding-ada-002', metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('model_name'), 'exclude': lambda f: f is None }})
    r"""The name of the model to use for embedding"""
    


class DestinationWeaviateSchemasEmbeddingEmbedding6Mode(str, Enum):
    FAKE = 'fake'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class DestinationWeaviateFake:
    r"""Use a fake embedding made out of random vectors with 1536 embedding dimensions. This is useful for testing the data pipeline without incurring any costs."""
    MODE: Final[Optional[DestinationWeaviateSchemasEmbeddingEmbedding6Mode]] = dataclasses.field(default=DestinationWeaviateSchemasEmbeddingEmbedding6Mode.FAKE, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('mode'), 'exclude': lambda f: f is None }})
    


class DestinationWeaviateSchemasEmbeddingEmbedding5Mode(str, Enum):
    FROM_FIELD = 'from_field'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class DestinationWeaviateFromField:
    r"""Use a field in the record as the embedding. This is useful if you already have an embedding for your data and want to store it in the vector store."""
    dimensions: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('dimensions') }})
    r"""The number of dimensions the embedding model is generating"""
    field_name: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('field_name') }})
    r"""Name of the field in the record that contains the embedding"""
    MODE: Final[Optional[DestinationWeaviateSchemasEmbeddingEmbedding5Mode]] = dataclasses.field(default=DestinationWeaviateSchemasEmbeddingEmbedding5Mode.FROM_FIELD, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('mode'), 'exclude': lambda f: f is None }})
    


class DestinationWeaviateSchemasEmbeddingEmbeddingMode(str, Enum):
    COHERE = 'cohere'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class DestinationWeaviateCohere:
    r"""Use the Cohere API to embed text."""
    cohere_key: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('cohere_key') }})
    MODE: Final[Optional[DestinationWeaviateSchemasEmbeddingEmbeddingMode]] = dataclasses.field(default=DestinationWeaviateSchemasEmbeddingEmbeddingMode.COHERE, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('mode'), 'exclude': lambda f: f is None }})
    


class DestinationWeaviateSchemasEmbeddingMode(str, Enum):
    OPENAI = 'openai'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class DestinationWeaviateOpenAI:
    r"""Use the OpenAI API to embed text. This option is using the text-embedding-ada-002 model with 1536 embedding dimensions."""
    openai_key: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('openai_key') }})
    MODE: Final[Optional[DestinationWeaviateSchemasEmbeddingMode]] = dataclasses.field(default=DestinationWeaviateSchemasEmbeddingMode.OPENAI, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('mode'), 'exclude': lambda f: f is None }})
    


class DestinationWeaviateSchemasMode(str, Enum):
    AZURE_OPENAI = 'azure_openai'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class DestinationWeaviateAzureOpenAI:
    r"""Use the Azure-hosted OpenAI API to embed text. This option is using the text-embedding-ada-002 model with 1536 embedding dimensions."""
    api_base: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('api_base') }})
    r"""The base URL for your Azure OpenAI resource.  You can find this in the Azure portal under your Azure OpenAI resource"""
    deployment: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('deployment') }})
    r"""The deployment for your Azure OpenAI resource.  You can find this in the Azure portal under your Azure OpenAI resource"""
    openai_key: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('openai_key') }})
    r"""The API key for your Azure OpenAI resource.  You can find this in the Azure portal under your Azure OpenAI resource"""
    MODE: Final[Optional[DestinationWeaviateSchemasMode]] = dataclasses.field(default=DestinationWeaviateSchemasMode.AZURE_OPENAI, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('mode'), 'exclude': lambda f: f is None }})
    


class DestinationWeaviateMode(str, Enum):
    NO_EMBEDDING = 'no_embedding'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class NoExternalEmbedding:
    r"""Do not calculate and pass embeddings to Weaviate. Suitable for clusters with configured vectorizers to calculate embeddings within Weaviate or for classes that should only support regular text search."""
    MODE: Final[Optional[DestinationWeaviateMode]] = dataclasses.field(default=DestinationWeaviateMode.NO_EMBEDDING, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('mode'), 'exclude': lambda f: f is None }})
    



@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class Header:
    header_key: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('header_key') }})
    value: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('value') }})
    


class DestinationWeaviateSchemasIndexingAuthAuthenticationMode(str, Enum):
    NO_AUTH = 'no_auth'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class NoAuthentication:
    r"""Do not authenticate (suitable for locally running test clusters, do not use for clusters with public IP addresses)"""
    MODE: Final[Optional[DestinationWeaviateSchemasIndexingAuthAuthenticationMode]] = dataclasses.field(default=DestinationWeaviateSchemasIndexingAuthAuthenticationMode.NO_AUTH, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('mode'), 'exclude': lambda f: f is None }})
    


class DestinationWeaviateSchemasIndexingAuthMode(str, Enum):
    USERNAME_PASSWORD = 'username_password'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class DestinationWeaviateUsernamePassword:
    r"""Authenticate using username and password (suitable for self-managed Weaviate clusters)"""
    password: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('password') }})
    r"""Password for the Weaviate cluster"""
    username: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('username') }})
    r"""Username for the Weaviate cluster"""
    MODE: Final[Optional[DestinationWeaviateSchemasIndexingAuthMode]] = dataclasses.field(default=DestinationWeaviateSchemasIndexingAuthMode.USERNAME_PASSWORD, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('mode'), 'exclude': lambda f: f is None }})
    


class DestinationWeaviateSchemasIndexingMode(str, Enum):
    TOKEN = 'token'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class DestinationWeaviateAPIToken:
    r"""Authenticate using an API token (suitable for Weaviate Cloud)"""
    token: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('token') }})
    r"""API Token for the Weaviate instance"""
    MODE: Final[Optional[DestinationWeaviateSchemasIndexingMode]] = dataclasses.field(default=DestinationWeaviateSchemasIndexingMode.TOKEN, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('mode'), 'exclude': lambda f: f is None }})
    


class DefaultVectorizer(str, Enum):
    r"""The vectorizer to use if new classes need to be created"""
    NONE = 'none'
    TEXT2VEC_COHERE = 'text2vec-cohere'
    TEXT2VEC_HUGGINGFACE = 'text2vec-huggingface'
    TEXT2VEC_OPENAI = 'text2vec-openai'
    TEXT2VEC_PALM = 'text2vec-palm'
    TEXT2VEC_CONTEXTIONARY = 'text2vec-contextionary'
    TEXT2VEC_TRANSFORMERS = 'text2vec-transformers'
    TEXT2VEC_GPT4ALL = 'text2vec-gpt4all'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class DestinationWeaviateIndexing:
    r"""Indexing configuration"""
    auth: Union[DestinationWeaviateAPIToken, DestinationWeaviateUsernamePassword, NoAuthentication] = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('auth') }})
    r"""Authentication method"""
    host: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('host') }})
    r"""The public endpoint of the Weaviate cluster."""
    additional_headers: Optional[List[Header]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('additional_headers'), 'exclude': lambda f: f is None }})
    r"""Additional HTTP headers to send with every request."""
    batch_size: Optional[int] = dataclasses.field(default=128, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('batch_size'), 'exclude': lambda f: f is None }})
    r"""The number of records to send to Weaviate in each batch"""
    default_vectorizer: Optional[DefaultVectorizer] = dataclasses.field(default=DefaultVectorizer.NONE, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('default_vectorizer'), 'exclude': lambda f: f is None }})
    r"""The vectorizer to use if new classes need to be created"""
    text_field: Optional[str] = dataclasses.field(default='text', metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('text_field'), 'exclude': lambda f: f is None }})
    r"""The field in the object that contains the embedded text"""
    



@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class DestinationWeaviateFieldNameMappingConfigModel:
    from_field: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('from_field') }})
    r"""The field name in the source"""
    to_field: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('to_field') }})
    r"""The field name to use in the destination"""
    


class DestinationWeaviateLanguage(str, Enum):
    r"""Split code in suitable places based on the programming language"""
    CPP = 'cpp'
    GO = 'go'
    JAVA = 'java'
    JS = 'js'
    PHP = 'php'
    PROTO = 'proto'
    PYTHON = 'python'
    RST = 'rst'
    RUBY = 'ruby'
    RUST = 'rust'
    SCALA = 'scala'
    SWIFT = 'swift'
    MARKDOWN = 'markdown'
    LATEX = 'latex'
    HTML = 'html'
    SOL = 'sol'

class DestinationWeaviateSchemasProcessingTextSplitterTextSplitterMode(str, Enum):
    CODE = 'code'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class DestinationWeaviateByProgrammingLanguage:
    r"""Split the text by suitable delimiters based on the programming language. This is useful for splitting code into chunks."""
    language: DestinationWeaviateLanguage = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('language') }})
    r"""Split code in suitable places based on the programming language"""
    MODE: Final[Optional[DestinationWeaviateSchemasProcessingTextSplitterTextSplitterMode]] = dataclasses.field(default=DestinationWeaviateSchemasProcessingTextSplitterTextSplitterMode.CODE, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('mode'), 'exclude': lambda f: f is None }})
    


class DestinationWeaviateSchemasProcessingTextSplitterMode(str, Enum):
    MARKDOWN = 'markdown'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class DestinationWeaviateByMarkdownHeader:
    r"""Split the text by Markdown headers down to the specified header level. If the chunk size fits multiple sections, they will be combined into a single chunk."""
    MODE: Final[Optional[DestinationWeaviateSchemasProcessingTextSplitterMode]] = dataclasses.field(default=DestinationWeaviateSchemasProcessingTextSplitterMode.MARKDOWN, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('mode'), 'exclude': lambda f: f is None }})
    split_level: Optional[int] = dataclasses.field(default=1, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('split_level'), 'exclude': lambda f: f is None }})
    r"""Level of markdown headers to split text fields by. Headings down to the specified level will be used as split points"""
    


class DestinationWeaviateSchemasProcessingMode(str, Enum):
    SEPARATOR = 'separator'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class DestinationWeaviateBySeparator:
    r"""Split the text by the list of separators until the chunk size is reached, using the earlier mentioned separators where possible. This is useful for splitting text fields by paragraphs, sentences, words, etc."""
    keep_separator: Optional[bool] = dataclasses.field(default=False, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('keep_separator'), 'exclude': lambda f: f is None }})
    r"""Whether to keep the separator in the resulting chunks"""
    MODE: Final[Optional[DestinationWeaviateSchemasProcessingMode]] = dataclasses.field(default=DestinationWeaviateSchemasProcessingMode.SEPARATOR, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('mode'), 'exclude': lambda f: f is None }})
    separators: Optional[List[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('separators'), 'exclude': lambda f: f is None }})
    r"""List of separator strings to split text fields by. The separator itself needs to be wrapped in double quotes, e.g. to split by the dot character, use \\".\\". To split by a newline, use \\"\n\\"."""
    



@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class DestinationWeaviateProcessingConfigModel:
    chunk_size: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('chunk_size') }})
    r"""Size of chunks in tokens to store in vector store (make sure it is not too big for the context if your LLM)"""
    chunk_overlap: Optional[int] = dataclasses.field(default=0, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('chunk_overlap'), 'exclude': lambda f: f is None }})
    r"""Size of overlap between chunks in tokens to store in vector store to better capture relevant context"""
    field_name_mappings: Optional[List[DestinationWeaviateFieldNameMappingConfigModel]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('field_name_mappings'), 'exclude': lambda f: f is None }})
    r"""List of fields to rename. Not applicable for nested fields, but can be used to rename fields already flattened via dot notation."""
    metadata_fields: Optional[List[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('metadata_fields'), 'exclude': lambda f: f is None }})
    r"""List of fields in the record that should be stored as metadata. The field list is applied to all streams in the same way and non-existing fields are ignored. If none are defined, all fields are considered metadata fields. When specifying text fields, you can access nested fields in the record by using dot notation, e.g. `user.name` will access the `name` field in the `user` object. It's also possible to use wildcards to access all fields in an object, e.g. `users.*.name` will access all `names` fields in all entries of the `users` array. When specifying nested paths, all matching values are flattened into an array set to a field named by the path."""
    text_fields: Optional[List[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('text_fields'), 'exclude': lambda f: f is None }})
    r"""List of fields in the record that should be used to calculate the embedding. The field list is applied to all streams in the same way and non-existing fields are ignored. If none are defined, all fields are considered text fields. When specifying text fields, you can access nested fields in the record by using dot notation, e.g. `user.name` will access the `name` field in the `user` object. It's also possible to use wildcards to access all fields in an object, e.g. `users.*.name` will access all `names` fields in all entries of the `users` array."""
    text_splitter: Optional[Union[DestinationWeaviateBySeparator, DestinationWeaviateByMarkdownHeader, DestinationWeaviateByProgrammingLanguage]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('text_splitter'), 'exclude': lambda f: f is None }})
    r"""Split text fields into chunks based on the specified method."""
    



@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class DestinationWeaviate:
    embedding: Union[NoExternalEmbedding, DestinationWeaviateAzureOpenAI, DestinationWeaviateOpenAI, DestinationWeaviateCohere, DestinationWeaviateFromField, DestinationWeaviateFake, DestinationWeaviateOpenAICompatible] = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('embedding') }})
    r"""Embedding configuration"""
    indexing: DestinationWeaviateIndexing = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('indexing') }})
    r"""Indexing configuration"""
    processing: DestinationWeaviateProcessingConfigModel = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('processing') }})
    DESTINATION_TYPE: Final[Weaviate] = dataclasses.field(default=Weaviate.WEAVIATE, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('destinationType') }})
    

